{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "IMDB_data = pd.read_csv(\"IMDB Dataset.csv\")  # Replace with the correct path to your dataset\n",
    "\n",
    "# Preprocessing functions\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords_l = stopwords.words(\"english\")\n",
    "token = ToktokTokenizer()\n",
    "\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    clean_text = soup.get_text()\n",
    "    clean_text = re.sub(r'[^A-Za-z0-9\\s]+', '', clean_text)\n",
    "    words = clean_text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Clean the reviews\n",
    "IMDB_data['review'] = IMDB_data['review'].apply(remove_html)\n",
    "\n",
    "# Encode sentiment column to binary (positive=1, negative=0)\n",
    "label_encoder = LabelBinarizer()\n",
    "IMDB_data['sentiment'] = label_encoder.fit_transform(IMDB_data['sentiment'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(IMDB_data['review'], IMDB_data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression using CountVectorizer\n",
    "countVec = CountVectorizer(min_df=0.0, max_df=1, binary=False, ngram_range=(1, 3))\n",
    "cv_train = countVec.fit_transform(train_X)\n",
    "cv_test = countVec.transform(test_X)\n",
    "\n",
    "log_reg_cv = LogisticRegression(max_iter=1000)\n",
    "log_reg_cv.fit(cv_train, train_Y)\n",
    "\n",
    "# Save Logistic Regression model and CountVectorizer\n",
    "with open('logistic_reg_countvec.pkl', 'wb') as f:\n",
    "    pickle.dump(log_reg_cv, f)\n",
    "    pickle.dump(countVec, f)\n",
    "print(\"Logistic Regression with CountVectorizer model saved.\")\n",
    "\n",
    "# Logistic Regression using TfidfVectorizer\n",
    "tfidfvec = TfidfVectorizer(min_df=0.0, max_df=1, binary=False, ngram_range=(1, 3))\n",
    "tfidf_train = tfidfvec.fit_transform(train_X)\n",
    "tfidf_test = tfidfvec.transform(test_X)\n",
    "\n",
    "log_reg_tfidf = LogisticRegression(max_iter=1000)\n",
    "log_reg_tfidf.fit(tfidf_train, train_Y)\n",
    "\n",
    "# Save Logistic Regression model and TfidfVectorizer\n",
    "with open('logistic_reg_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(log_reg_tfidf, f)\n",
    "    pickle.dump(tfidfvec, f)\n",
    "print(\"Logistic Regression with TfidfVectorizer model saved.\")\n",
    "\n",
    "# Multinomial Naive Bayes using CountVectorizer\n",
    "nb_model_cv = MultinomialNB()\n",
    "nb_model_cv.fit(cv_train, train_Y)\n",
    "\n",
    "# Save Naive Bayes model and CountVectorizer\n",
    "with open('nb_model_countvec.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_model_cv, f)\n",
    "    pickle.dump(countVec, f)\n",
    "print(\"Naive Bayes with CountVectorizer model saved.\")\n",
    "\n",
    "# Multinomial Naive Bayes using TfidfVectorizer\n",
    "nb_model_tfidf = MultinomialNB()\n",
    "nb_model_tfidf.fit(tfidf_train, train_Y)\n",
    "\n",
    "# Save Naive Bayes model and TfidfVectorizer\n",
    "with open('nb_model_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_model_tfidf, f)\n",
    "    pickle.dump(tfidfvec, f)\n",
    "print(\"Naive Bayes with TfidfVectorizer model saved.\")\n",
    "\n",
    "# Voting Classifier using Logistic Regression and Naive Bayes\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('log_reg_cv', log_reg_cv),\n",
    "    ('log_reg_tfidf', log_reg_tfidf),\n",
    "    ('nb_model_cv', nb_model_cv),\n",
    "    ('nb_model_tfidf', nb_model_tfidf)\n",
    "], voting='hard')\n",
    "voting_clf.fit(tfidf_train, train_Y)\n",
    "\n",
    "# Save Voting Classifier model\n",
    "with open('voting_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(voting_clf, f)\n",
    "print(\"Voting Classifier model saved.\")\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    report = classification_report(test_labels, predictions)\n",
    "    return accuracy, report\n",
    "\n",
    "# Evaluate Logistic Regression with CountVectorizer\n",
    "log_reg_accuracy, log_reg_report = evaluate_model(log_reg_cv, cv_test, test_Y)\n",
    "print(f\"Logistic Regression with CountVectorizer Accuracy: {log_reg_accuracy}\")\n",
    "print(log_reg_report)\n",
    "\n",
    "# Evaluate Logistic Regression with TfidfVectorizer\n",
    "log_reg_tfidf_accuracy, log_reg_tfidf_report = evaluate_model(log_reg_tfidf, tfidf_test, test_Y)\n",
    "print(f\"Logistic Regression with TfidfVectorizer Accuracy: {log_reg_tfidf_accuracy}\")\n",
    "print(log_reg_tfidf_report)\n",
    "\n",
    "# Evaluate Naive Bayes with CountVectorizer\n",
    "nb_accuracy, nb_report = evaluate_model(nb_model_cv, cv_test, test_Y)\n",
    "print(f\"Naive Bayes with CountVectorizer Accuracy: {nb_accuracy}\")\n",
    "print(nb_report)\n",
    "\n",
    "# Evaluate Naive Bayes with TfidfVectorizer\n",
    "nb_tfidf_accuracy, nb_tfidf_report = evaluate_model(nb_model_tfidf, tfidf_test, test_Y)\n",
    "print(f\"Naive Bayes with TfidfVectorizer Accuracy: {nb_tfidf_accuracy}\")\n",
    "print(nb_tfidf_report)\n",
    "\n",
    "# Evaluate Voting Classifier\n",
    "voting_accuracy, voting_report = evaluate_model(voting_clf, tfidf_test, test_Y)\n",
    "print(f\"Voting Classifier Accuracy: {voting_accuracy}\")\n",
    "print(voting_report)\n",
    "\n",
    "# Decision Tree using CountVectorizer\n",
    "countVec = CountVectorizer(min_df=0.0, max_df=1.0, binary=False, ngram_range=(1, 3))\n",
    "cv_train = countVec.fit_transform(train_X)\n",
    "cv_test = countVec.transform(test_X)\n",
    "\n",
    "# Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(cv_train, train_Y)\n",
    "\n",
    "# Save Decision Tree model and CountVectorizer\n",
    "with open('decision_tree_model.pkl', 'wb') as f:\n",
    "    pickle.dump(decision_tree, f)\n",
    "    pickle.dump(countVec, f)\n",
    "print(\"Decision Tree with CountVectorizer model saved.\")\n",
    "\n",
    "# Evaluate Decision Tree model\n",
    "decision_tree_accuracy, decision_tree_report = evaluate_model(decision_tree, cv_test, test_Y)\n",
    "print(f\"Decision Tree with CountVectorizer Accuracy: {decision_tree_accuracy}\")\n",
    "print(decision_tree_report)\n",
    "\n",
    "# Decision Tree using TfidfVectorizer\n",
    "tfidfvec = TfidfVectorizer(min_df=0.0, max_df=1.0, binary=False, ngram_range=(1, 3))\n",
    "tfidf_train = tfidfvec.fit_transform(train_X)\n",
    "tfidf_test = tfidfvec.transform(test_X)\n",
    "\n",
    "# Train Decision Tree classifier with TfidfVectorizer\n",
    "decision_tree_tfidf = DecisionTreeClassifier()\n",
    "decision_tree_tfidf.fit(tfidf_train, train_Y)\n",
    "\n",
    "# Save Decision Tree model and TfidfVectorizer\n",
    "with open('decision_tree_tfidf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(decision_tree_tfidf, f)\n",
    "    pickle.dump(tfidfvec, f)\n",
    "print(\"Decision Tree with TfidfVectorizer model saved.\")\n",
    "\n",
    "# Evaluate Decision Tree with TfidfVectorizer\n",
    "decision_tree_tfidf_accuracy, decision_tree_tfidf_report = evaluate_model(decision_tree_tfidf, tfidf_test, test_Y)\n",
    "print(f\"Decision Tree with TfidfVectorizer Accuracy: {decision_tree_tfidf_accuracy}\")\n",
    "print(decision_tree_tfidf_report)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def plot_classification_report(report, model_name):\n",
    "    # Convert the classification report into a pandas DataFrame for easier plotting\n",
    "    report_data = []\n",
    "    for label, metrics in report.items():\n",
    "        if label in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "            continue\n",
    "        report_data.append([label, metrics['precision'], metrics['recall'], metrics['f1-score']])\n",
    "    df = pd.DataFrame(report_data, columns=['Label', 'Precision', 'Recall', 'F1-Score'])\n",
    "\n",
    "\n",
    "\n",
    "    # Plot Precision, Recall, and F1-Score\n",
    "\n",
    "    df.plot(x='Label', kind='bar', figsize=(10, 6), ylim=(0, 1), colormap='Set3')\n",
    "    plt.title(f'{model_name} Classification Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "\n",
    "    # Create a dictionary of model names and their accuracies\n",
    "model_accuracies = {\n",
    "    'Logistic Regression (CountVectorizer)': log_reg_accuracy,\n",
    "    'Logistic Regression (TfidfVectorizer)': log_reg_tfidf_accuracy,\n",
    "    'Naive Bayes (CountVectorizer)': nb_accuracy,\n",
    "    'Decision Tree (CountVectorizer)': decision_tree_accuracy\n",
    "}\n",
    "\n",
    "# Plot the accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(list(model_accuracies.keys()), list(model_accuracies.values()), color=['blue', 'green', 'orange', 'red'])\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlim(0.5, 1.0)  # To better visualize, assuming accuracies above 50%\n",
    "plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.title(f\"Confusion Matrix: {model_name}\")\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot for Decision Tree (CountVectorizer)\n",
    "decision_tree_report_dict = classification_report(test_Y, decision_tree.predict(cv_test), output_dict=True)\n",
    "plot_classification_report(decision_tree_report_dict, \"Decision Tree (CountVectorizer)\")\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Write the test code to a file named model.py\n",
    "with open(\"model.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def dummy_data():\n",
    "    data = {'review': ['<html>Good movie!</html>', 'Bad movie, very bad', 'Great movie, I loved it!'], \n",
    "            'sentiment': ['positive', 'negative', 'positive']}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Test data loading function\n",
    "def test_load_data(dummy_data):\n",
    "    assert len(dummy_data) == 3\n",
    "    assert 'review' in dummy_data.columns\n",
    "    assert 'sentiment' in dummy_data.columns\n",
    "\"\"\")\n",
    "\n",
    "# Step 3: Run pytest\n",
    "!pytest -v model.py \n",
    "\n",
    "# Step 1: Create a test file named test_module.py with the test function and fixture\n",
    "with open(\"test_module.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "import pandas as pd\n",
    "import pytest\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "@pytest.fixture\n",
    "def dummy_data():\n",
    "    data = {'review': ['<html>Good movie!</html>', 'Bad movie, very bad', 'Great movie, I loved it!'], \n",
    "            'sentiment': ['positive', 'negative', 'positive']}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def test_logistic_regression_training(dummy_data):\n",
    "    # Step 1: Vectorize the text data\n",
    "    countVec = CountVectorizer(min_df=0.0, max_df=1, binary=False, ngram_range=(1, 3))\n",
    "    cv_train = countVec.fit_transform(dummy_data['review'])\n",
    "\n",
    "    # Step 2: Train a Logistic Regression model\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(cv_train, [1, 0, 1])\n",
    "    \n",
    "    # Step 3: Assert that the model can make predictions on new data\n",
    "    test_data = countVec.transform(['new review'])\n",
    "    assert log_reg.predict(test_data).shape == (1,)\n",
    "\"\"\")\n",
    "\n",
    "# Step 2: Run pytest to validate the test function\n",
    "!pytest -v test_module.py \n",
    "\n",
    "\n",
    "# Step 1: Install pytest and scikit-learn\n",
    "!pip install pytest scikit-learn\n",
    "\n",
    "# Step 2: Create your_module.py with remove_html\n",
    "with open(\"your_module.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "import re\n",
    "\n",
    "def remove_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\"\"\")\n",
    "\n",
    "# Step 3: Create test_module.py with test cases\n",
    "with open(\"test_module.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pytest\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "@pytest.fixture\n",
    "def dummy_data():\n",
    "    data = {'review': ['<html>Good movie!</html>', 'Bad movie, very bad', 'Great movie, I loved it!'], \n",
    "            'sentiment': ['positive', 'negative', 'positive']}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def test_saving_logistic_regression_model(tmpdir, dummy_data):\n",
    "    from your_module import remove_html\n",
    "\n",
    "    # Clean data\n",
    "    dummy_data['review'] = dummy_data['review'].apply(remove_html)\n",
    "\n",
    "    # Vectorize data\n",
    "    countVec = CountVectorizer(min_df=0.0, max_df=1, binary=False, ngram_range=(1, 3))\n",
    "    cv_train = countVec.fit_transform(dummy_data['review'])\n",
    "    \n",
    "    # Train Logistic Regression model\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(cv_train, [1, 0, 1])\n",
    "\n",
    "    # Save the model and vectorizer\n",
    "    save_path = tmpdir.join('logistic_reg_countvec.pkl')\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(log_reg, f)\n",
    "        pickle.dump(countVec, f)\n",
    "\n",
    "    # Check if the file is created\n",
    "    assert os.path.exists(save_path)\n",
    "\n",
    "    # Load the model and vectorizer back\n",
    "    with open(save_path, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "        loaded_vectorizer = pickle.load(f)\n",
    "\n",
    "    # Assert that the loaded model and vectorizer are not None\n",
    "    assert loaded_model is not None\n",
    "    assert loaded_vectorizer is not None\n",
    "\n",
    "    # Assert that the loaded model can predict correctly\n",
    "    test_data = loaded_vectorizer.transform(['new review'])\n",
    "    assert loaded_model.predict(test_data).shape == (1,)\n",
    "\"\"\")\n",
    "\n",
    "# Step 4: Run pytest\n",
    "!pytest -v test_module.py\n",
    "\n",
    "# Step 2: Create the module file your_module.py with the remove_html function\n",
    "with open(\"your_module.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "import re\n",
    "\n",
    "def remove_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\"\"\")\n",
    "\n",
    "# Step 3: Create a test file named test_module.py with test_remove_html\n",
    "with open(\"test_module.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "def test_remove_html():\n",
    "    from your_module import remove_html\n",
    "    \n",
    "    html_string = \"<p>This is a <strong>test</strong></p>\"\n",
    "    expected_output = \"This is a test\"\n",
    "    \n",
    "    assert remove_html(html_string) == expected_output\n",
    "    print(\"Test passed!\")\n",
    "\"\"\")\n",
    "\n",
    "# Step 4: Run pytest\n",
    "!pytest -v test_module.py "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
